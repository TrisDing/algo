# LRU Cache

> LRU Cache discards the least recently used items first. This algorithm requires keeping track of what was used when, which is expensive if one wants to make sure the algorithm always discards the least recently used item.

```
      A    B    C    D    E    F    C    G
--------------------------------------------
[ ]  [A]  [B]  [C]  [D]  [E]  [F]  [C]  [G]
[ ]  [ ]  [A]  [B]  [C]  [D]  [E]  [F]  [C]
[ ]  [ ]  [ ]  [A]  [B]  [C]  [D]  [E]  [F]
[ ]  [ ]  [ ]  [ ]  [A]  [B]  [C]  [D]  [E]
[ ]  [ ]  [ ]  [ ]  [ ]  [A]  [B]  [B]  [D]
--------------------------------------------
                              [A]       [B]
```

- Native Implementation: Hash Table + Doubly LinkedList
- Python API Implementation: `collections.OrderedDict()`

| Operation | Time Complexity |
|-----------|:---------------:|
| Lookup    |      O(1)       |
| Update    |      O(1)       |

## LRU Cache Implementation
```py
class DoublyLinkedNode:
    def __init__(self, key=0, value=0):
        self.key = key
        self.value = value
        self.prev = None
        self.next = None

class LRUCache:

    def __init__(self, capacity: int):
        self.cache = {} # key -> DoublyLinkedNode
        self.head = DoublyLinkedNode()
        self.tail = DoublyLinkedNode()
        self.head.next = self.tail
        self.tail.prev = self.head
        self.capacity = capacity
        self.size = 0

    def get(self, key: int) -> int:
        if key not in self.cache:
            return -1
        # if key exists, locate node in cache, then move to head
        node = self.cache[key] # key is now most recently used
        self.moveToHead(node)
        return node.value

    def put(self, key: int, value: int) -> None:
        if key not in self.cache:
            node = DoublyLinkedNode(key, value)
            self.cache[key] = node
            self.addToHead(node)
            self.size += 1
            if self.size > self.capacity:
                # drop least recently used (tail)
                removed = self.removeTail()
                self.cache.pop(removed.key)
                self.size -= 1
        else:
            node = self.cache[key]
            node.value = value
            self.moveToHead(node)

    def addToHead(self, node: DoublyLinkedNode) -> None:
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node

    def removeNode(self, node: DoublyLinkedNode) -> None:
        node.prev.next = node.next
        node.next.prev = node.prev

    def moveToHead(self, node: DoublyLinkedNode) -> None:
        self.removeNode(node)
        self.addToHead(node)

    def removeTail(self) -> DoublyLinkedNode:
        node = self.tail.prev
        self.removeNode(node)
        return node
```

## Exercises
- [146. LRU Cache](https://leetcode.com/problems/lru-cache/)