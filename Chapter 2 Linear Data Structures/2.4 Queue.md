# Queue

> Queue is linear data structure which models a real world queue by having two primary operations, namely _enqueue_ and _dequeue_

- Queues support **first-in-first-out (FIFO)** for **inserts** and **deletes**
- Queues can efficiently track x most recently add elements and Breath first search (BFS graph) traversal
- Queues can be implemented using Array or LinkedList.

```
          front              back
            ⤵                ⤴
dequeue ← [data][data] ... [data] ← enqueue
```

| Operation | Time Complexity |
|-----------|:---------------:|
| Access    |      O(n)       |
| Search    |      O(n)       |
| Insertion |      O(1)       |
| Deletion  |      O(1)       |

## Queue Operations

```py
from collections import deque

queue = deque()      # create a double ended queue
queue.append(x)      # add x to the right side of the deque
queue.appendleft(x)  # add x to the left side of the deque, same as insert(0, x)
queue.pop()          # remove and return an element from the right side of the deque
queue.popleft()      # remove and return an element from the left side of the deque, same as pop(0)
queue[-1]            # peek right side of the deque
queue[0]             # peek left side of the deque
```

## Queue Implementation

```py
class Queue:
    def __init__(self):
        self.queue = []

    def enqueue(self, item):
        self.queue.append(item)

    def dequeue(self):
        if self.size() == 0:
            return None
        return self.queue.popleft()

    def size(self):
        return len(self.queue)
```

### Circular Queue

A **circular queue** is the extended version of a regular queue where the last element is connected to the first element. Thus forming a circle-like structure. The circular queue solves the major limitation of the normal queue: after a bit of insertion and deletion, there will be non-usable empty space.

```py
class CircularQueue:
    def __init__(self, capacity: int):
        self.head = 0
        self.tail = 0
        self.size = 0
        self.queue = [0] * capacity

    def enQueue(self, value: int) -> bool:
        if self.isFull():
            return False
        self.queue[self.tail] = value
        self.tail = (self.tail + 1) % len(self.queue)
        self.size += 1
        return True

    def deQueue(self) -> int:
        if self.isEmpty():
            return -1
        value = self.queue[self.head]
        self.head = (self.head + 1) % len(self.queue)
        self.size -= 1
        return value

    def front(self) -> int:
        if self.isEmpty():
            return -1
        return self.queue[self.head]

    def rear(self) -> int:
        if self.isEmpty():
            return -1
        return self.queue[self.tail - 1]

    def isEmpty(self) -> bool:
        return self.size == 0

    def isFull(self) -> bool:
        return self.size == len(self.queue)
```

### Double Ended Queue (Deque)

**Deque** is a type of queue in which insertion and removal of elements can either be performed from the front or the rear. Thus, it does not follow the FIFO rule.

- Input Restricted Deque: input is restricted at a single end but allows deletion at both the ends.
- Output Restricted Deque: output is restricted at a single end but allows insertion at both the ends.

```py
class Deque:
    def __init__(self):
        self.queue = []

    def isEmpty(self):
        return self.queue == []

    def addRear(self, item):
        self.queue.append(item)

    def addFront(self, item):
        self.queue.insert(0, item)

    def removeFront(self):
        return self.queue.pop(0)

    def removeRear(self):
        return self.queue.pop()

    def size(self):
        return len(self.queue)
```

### Priority Queue

**Priority Queue** is a special type of queue in which each element is associated with a priority value, and elements are served on the basis of their _priority_. That is, higher priority elements are served first. However, if elements with the same priority occur, they are served according to their order in the queue.

Priority queue can be implemented using Array, Linked List, Heap, or Binary Search Tree. Among these data structures, Heap data structure provides an efficient implementation of priority queues.

```py
class PriorityQueue(Queue):
    def __init__(self):
        self.queue = []

    def size(self):
        return len(self.queue)

    def put(self, item):
        heappush(self.queue, item)

    def get(self):
        return heappop(self.queue)
```

### Concurrent Queue

Thread-safe queues are called **concurrent queues**. The simplest way to achieve this is to add **locks** to the `enqueue()` and `dequeue()` methods. But the concurrency of the lock granularity will be relatively low, and only one _put_ or _take_ operation is allowed at a time.

```py
from collections import deque
from threading import Lock, Condition

class ThreadSafeQueue:
    def __init__(self, maxsize=0):
        self.maxsize = maxsize
        self.queue = deque()

        # the additional attribute to protect the access of our queue
        self.mutex = Lock()

        # Notify not_empty whenever an item is added to the queue; a
        # thread waiting to get is notified then.
        self.not_empty = Condition(self.mutex)

        # Notify not_full whenever an item is removed from the queue;
        # a thread waiting to put is notified then.
        self.not_full = Condition(self.mutex)

    def size(self):
        # automatically acquire the lock when entering the block
        with self.mutex:
            return len(self.queue)
        # automatically release the lock when leaving the block

    def put(self, item):
        with self.not_full:
            if self.maxsize > 0:
                while self.size() >= self.maxsize:
                    self.not_full.wait()
            self.queue.append(item)
            self.not_empty.notify()

    def get(self):
        with self.not_empty:
            while not self.size():
                self.not_empty.wait()
            item = self.queue.popleft()
            self.not_full.notify()
            return item
```

### Blocking Queue

The **blocking queue** adds blocking operations on the basic queue. When the queue is empty, fetching data from the head of the queue will be blocked until there is some data in the queue. Likewise, if the queue is full, the operation of inserting data will be blocked until there is a free space in the queue.

We can easily implement the [producer-consumer](https://www.cs.cornell.edu/courses/cs3110/2010fa/lectures/lec18.html) model with help of the blocking queue.
```
<Consumer 1>  take
                    ↖
<Consumer 2>  take ← [data][data] ... [data][data] ← put <Producer>
                    ↙
<Consumer 3>  take
```

**Using threading.Lock**
```py
from collections import deque
from threading import Lock

class BoundedBlockingQueue(object):
    def __init__(self, capacity: int):
        self.enlock = Lock()
        self.delock = Lock()
        self.queue = deque()
        self.capacity = capacity
        self.delock.acquire()

    def enqueue(self, element: int) -> None:
        self.enlock.acquire()
        self.queue.append(element)
        if len(self.queue) < self.capacity:
            self.enlock.release()
        if self.delock.locked():
            self.delock.release()

    def dequeue(self) -> int:
        self.delock.acquire()
        value = self.queue.popleft()
        if len(self.queue):
            self.delock.release()
        if value and self.enlock.locked():
            self.enlock.release()
        return value

    def size(self) -> int:
        return len(self.queue)
```

**Using threading.Condition**
```py
from collections import deque
from threading import Condition

class BoundedBlockingQueue(object):
    def __init__(self, capacity: int):
        self.cond = Condition()
        self.queue = deque()
        self.capacity = capacity

    def enqueue(self, element: int) -> None:
        with self.cond:
            self.cond.wait_for(lambda: len(self.queue) < self.capacity)
            self.queue.append(element)
            self.cond.notify_all()

    def dequeue(self) -> int:
        with self.cond:
            self.cond.wait_for(lambda: len(self.queue) > 0)
            value = self.queue.popleft()
            self.cond.notify_all()
            return value

    def size(self) -> int:
        return len(self.queue)
```

## Algorithms

**Mono Queue**
```py
class monoQueue:
    def __init__(self):
        self.queue = deque()

    def push(self, x):
        while self.queue and self.queue[-1] < x:
            self.queue.pop()
        self.queue.append(x)

    def pop(self, x):
        if self.queue and self.queue[0] == x:
            self.queue.popleft()

    def max(self):
        return self.queue[0]

def slidingWindowMaximum(self, nums: List[int], k: int) -> List[int]:
    res = []
    window = MonoQueue()
    for i in range(len(nums)):
        if i < k - 1:
            window.push(nums[i])
        else:
            window.push(nums[i])
            res.append(window.max())
            window.pop(nums[i - k + 1])
    return res
```

## Exercises

- [225. Implement Stack using Queues](https://leetcode.com/problems/implement-stack-using-queues/)
- [239. Sliding Window Maximum](https://leetcode.com/problems/sliding-window-maximum/)
- [406. Queue Reconstruction by Height](https://leetcode.com/problems/queue-reconstruction-by-height/)
